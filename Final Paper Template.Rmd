---
title: "Final Paper"
author: "STOR 320.01 Group 21"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: html_document
---

```{r setup, include=FALSE, message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "D:/Document/2018-2019/Stor320/Final Project/")
library(tidyverse)
library(dplyr)
library(plyr)
library(tidyr)
library(ggplot2)
library(maps)
library(mapproj)
devtools::install_github("wmurphyrd/fiftystater")
library(fiftystater)
library(randomForest) 
library(ranger)
library(readr)
library(tibble)
library(scales)
library(ggrepel)
devtools::install_github("haozhu233/kableExtra")
library(knitr)
library(kableExtra)
```

```{r, echo=F, message=FALSE,warning=FALSE}
dataOrg <- read_csv("D:/Document/2018-2019/Stor320/Final Project/PWD_Disclosure_Data_FY2018_EOY.csv")

dataCleanModel <- dataOrg %>% select(`EMPLOYER _CITY`,`EMPLOYER _STATE`,`EMPLOYER _COUNTRY`,JOB_TITLE,WORK_HOUR_NUM_BASIC,WORK_HOUR_NUM_OVERTIME, TRAVEL_REQUIRED,PRIMARY_EDUCATION_LEVEL,MAJOR,SECOND_DIPLOMA,SECOND_DIPLOMA_MAJOR,TRAINING_REQUIRED,NUMBER_OF_MONTHS_TRAINING,EMP_EXPERIENCE_REQUIRED,EMP_EXPERIENCE_MONTHS,PWD_WAGE_RATE,`SUGGESTED _SOC_CODE`)

dataCleanModel <- dataCleanModel %>% select(-SECOND_DIPLOMA_MAJOR, -WORK_HOUR_NUM_BASIC, -WORK_HOUR_NUM_OVERTIME)
dataCleanModel <- dataCleanModel %>% select(-MAJOR)
dataCleanModel = dataCleanModel %>% mutate_if(is.character, as.factor)

dataCleanModel = dataCleanModel %>% drop_na(PWD_WAGE_RATE)
dataCleanModel$NUMBER_OF_MONTHS_TRAINING[is.na(dataCleanModel$NUMBER_OF_MONTHS_TRAINING)] <- 0
dataCleanModel$EMP_EXPERIENCE_MONTHS[is.na(dataCleanModel$EMP_EXPERIENCE_MONTHS)] <- 0
dataCleanModel$EMP_EXPERIENCE_MONTHS[is.na(dataCleanModel$EMP_EXPERIENCE_MONTHS)] <- 0
dataCleanModel = dataCleanModel %>% drop_na()
dataCleanModel = dataCleanModel %>% dplyr::rename(SUGGESTED_SOC_CODE = `SUGGESTED _SOC_CODE`, EMPLOYER_CITY = `EMPLOYER _CITY`, EMPLOYER_STATE = `EMPLOYER _STATE`, EMPLOYER_COUNTRY = `EMPLOYER _COUNTRY`)
dataCleanModel <- tibble::rowid_to_column(dataCleanModel, "ID")

smp_size <- floor(0.75 * nrow(dataCleanModel))
set.seed(123)
train_ind <- sample(seq_len(nrow(dataCleanModel)), size = smp_size)
train <- dataCleanModel[train_ind, ]
test <- dataCleanModel[-train_ind, ]

rf = ranger(formula = PWD_WAGE_RATE ~ .-ID, data = train, num.trees = 500, importance = "impurity", seed = 1,respect.unordered.factors = "ignore",write.forest = TRUE)
p<-predict(rf,test)

imp = importance(rf)
imp = as_tibble(imp)
imp$label = names(importance(rf))
#head(imp)
graph1imp = ggplot(imp) + geom_col(mapping = aes(x=label, y=value))+
  ylab("Importance") + 
  xlab("Parameter")+
  theme_light()+ggtitle("Importance of Parameters") + 
  theme_classic()+
  theme(
    plot.title = element_text(color="blue", size=14, face="bold.italic"),
    axis.title.x = element_text(color="blue", size=14, face="bold"),
    axis.title.y = element_text(color="blue", size=14, face="bold",margin = ggplot2::margin(t = 0, r = 10, b = 0, l = 0)),
    axis.text.x = element_text(angle=0),
    axis.ticks.x = element_blank()
    )+
  coord_flip()

paco=p$predictions
tibPac <- as_tibble(paco)

graph1pred = ggplot(tibPac) + geom_boxplot(mapping = aes(y=value))   + 
  ylab("Wage Rate (Dollars)") + 
  theme_light()+ggtitle("Predicted Wage Rates") + 
  theme_classic()+
  theme(
    plot.title = element_text(color="blue", size=14, face="bold.italic"),
    axis.title.x = element_text(color="blue", size=14, face="bold"),
    axis.title.y = element_text(color="blue", size=14, face="bold",margin = ggplot2::margin(t = 0, r = 20, b = 0, l = 0)),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
    )+
  scale_y_continuous(breaks=seq(0,300000,100000),labels =  dollar_format())

graph1actual = dataCleanModel %>% filter(PWD_WAGE_RATE<500000) %>% ggplot() + geom_boxplot(mapping = aes(y=PWD_WAGE_RATE))   + 
  ylab("Wage Rate (Dollars)") + 
  theme_light()+ggtitle("Actual Wage Rates") + 
  theme_classic()+
  theme(
    plot.title = element_text(color="blue", size=14, face="bold.italic"),
    axis.title.x = element_text(color="blue", size=14, face="bold"),
    axis.title.y = element_text(color="blue", size=14, face="bold",margin = ggplot2::margin(t = 0, r = 20, b = 0, l = 0)),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
    )+
  scale_y_continuous(breaks=seq(0,300000,100000),labels =  dollar_format())
```

```{r  echo=F}
data <- read.csv("D:/Document/2018-2019/Stor320/Final Project/h1data.csv", as.is=T)
data = dplyr::rename(data,VISA_CLASS = `ï..VISA_CLASS`)
states <- map_data("state")
counties <- map_data("county")
ca_df <- subset(states, region == "california")
ca_county <- subset(counties, region == "california")
ca_city <- subset(us.cities, country.etc == "CA" & pop > 250000)
ca_city$name[ca_city$name == "Anaheim CA"] <- "Anaheim"
ca_city$name[ca_city$name == "Bakersfield CA"] <- "Bakersfield"
ca_city$name[ca_city$name == "Fresno CA"] <- "Fresno"
ca_city$name[ca_city$name == "Long Beach CA"] <- "Long Beach"
ca_city$name[ca_city$name == "Los Angeles CA"] <- "Los Angeles"
ca_city$name[ca_city$name == "Oakland CA"] <- "Oakland"
ca_city$name[ca_city$name == "Riverside CA"] <- "Riverside"
ca_city$name[ca_city$name == "Sacramento CA"] <- "Sacramento"
ca_city$name[ca_city$name == "San Diego CA"] <- "San Diego"
ca_city$name[ca_city$name == "San Francisco CA"] <- "San Francisco"
ca_city$name[ca_city$name == "San Jose CA"] <- "San Jose"
ca_city$name[ca_city$name == "Santa Ana CA"] <- "Santa Ana"
ca_city$name[ca_city$name == "Stockton CA"] <- "Stockton"
ca_base <- ggplot(data = ca_df, mapping = aes(x = long, y = lat, group = group)) + 
  coord_fixed(1.3) + 
  geom_polygon(color = "black", fill = "lightgray")
tx_df <- subset(states, region == "texas")
tx_county <- subset(counties, region == "texas")
tx_city <- subset(us.cities, country.etc == "TX" & pop > 250000)
tx_city$name[tx_city$name == "Arlington TX"] <- "Arlington"
tx_city$name[tx_city$name == "Austin TX"] <- "Austin"
tx_city$name[tx_city$name == "Corpus Christi TX"] <- "Corpus Christi"
tx_city$name[tx_city$name == "Dallas TX"] <- "Dallas"
tx_city$name[tx_city$name == "El Paso TX"] <- "El Paso"
tx_city$name[tx_city$name == "Fort Worth TX"] <- "Fort Worth"
tx_city$name[tx_city$name == "Houston TX"] <- "Houston"
tx_city$name[tx_city$name == "Plano TX"] <- "Plano"
tx_city$name[tx_city$name == "San Antonio TX"] <- "San Antonio"
tx_base <- ggplot(data = tx_df, mapping = aes(x = long, y = lat, group = group)) +
  coord_fixed(1.3) + 
  geom_polygon(color = "black", fill = "lightgray")
fl_df <- subset(states, region == "florida")
fl_county <- subset(counties, region == "florida")
fl_city <- subset(us.cities, country.etc == "FL" & pop > 250000 | name == "Orlando FL")
fl_city$name[fl_city$name == "Jacksonville FL"] <- "Jacksonville"
fl_city$name[fl_city$name == "Miami FL"] <- "Miami"
fl_city$name[fl_city$name == "Orlando FL"] <- "Orlando"
fl_city$name[fl_city$name == "Tampa FL"] <- "Tampa"
fl_base <- ggplot(data = fl_df, mapping = aes(x = long, y = lat, group = group)) +
  coord_fixed(1.3) + 
  geom_polygon(color = "black", fill = "lightgray")
drop_axes <- theme(
  axis.text = element_blank(),
  axis.line = element_blank(),
  axis.ticks = element_blank(),
  panel.border = element_blank(),
  panel.grid = element_blank(),
  axis.title = element_blank()
  )
cali <- data[grep("CALIFORNIA", data$PRIMARY_WORKSITE_STATE),]
cali$PRIMARY_WORKSITE_COUNTY <- tolower(cali$PRIMARY_WORKSITE_COUNTY)
cali_count <- aggregate(cbind(number_of_visas = VISA_CLASS) ~ PRIMARY_WORKSITE_COUNTY, 
          data = cali, 
          FUN = function(x){NROW(x)})
names(cali_count)[names(cali_count)=="PRIMARY_WORKSITE_COUNTY"] <- "subregion"
ca_final <- inner_join(ca_county, cali_count, by = "subregion")
ca_map <- ca_base + 
      geom_polygon(data = ca_final, aes(fill = number_of_visas), color = "white", size = .1) +
      geom_polygon(data = ca_county, fill = NA, color = "white", size = .1) +
      geom_polygon(color = "black", fill = NA) +
      scale_fill_gradient(low = "#56B1F7", high = "#132B43", guide = "colorbar") +
      theme_bw() +
      drop_axes
tex <- data[grep("TEXAS", data$PRIMARY_WORKSITE_STATE),]
tex$PRIMARY_WORKSITE_COUNTY <- tolower(tex$PRIMARY_WORKSITE_COUNTY)
tex_count <- aggregate(cbind(number_of_visas = VISA_CLASS) ~ PRIMARY_WORKSITE_COUNTY, 
          data = tex, 
          FUN = function(x){NROW(x)})
names(tex_count)[names(tex_count)=="PRIMARY_WORKSITE_COUNTY"] <- "subregion"
tx_final <- inner_join(tx_county, tex_count, by = "subregion")
tx_map <- tx_base + 
      geom_polygon(data = tx_final, aes(fill = number_of_visas), color = "white", size = .1) +
      geom_polygon(data = tx_county, fill = NA, color = "white", size = .1) +
      geom_polygon(color = "black", fill = NA) +
      scale_fill_gradient(low = "#56B1F7", high = "#132B43", guide = "colorbar") +
      theme_bw() +
      drop_axes
flo <- data[grep("FLORIDA", data$PRIMARY_WORKSITE_STATE),]
flo$PRIMARY_WORKSITE_COUNTY <- tolower(flo$PRIMARY_WORKSITE_COUNTY)
flo$PRIMARY_WORKSITE_COUNTY[flo$PRIMARY_WORKSITE_COUNTY == "miami dade"] <- "miami-dade"
flo_count <- aggregate(cbind(number_of_visas = VISA_CLASS) ~ PRIMARY_WORKSITE_COUNTY, 
          data = flo, 
          FUN = function(x){NROW(x)})
names(flo_count)[names(flo_count)=="PRIMARY_WORKSITE_COUNTY"] <- "subregion"
fl_final <- inner_join(fl_county, flo_count, by = "subregion")
fl_map <- fl_base + 
      geom_polygon(data = fl_final, aes(fill = number_of_visas), color = "white", size = .1) +
      geom_polygon(data = fl_county, fill = NA, color = "white", size = .1) +
      geom_polygon(color = "black", fill = NA) +
      scale_fill_gradient(low = "#56B1F7", high = "#132B43", guide = "colorbar") +
      theme_bw() +
      drop_axes
heatmap_ca = ca_map + geom_point(data = ca_city, aes(long, lat), inherit.aes = FALSE, color = "white", size = 1) + geom_label_repel(data = ca_city, aes(long, lat, label = name), size = 2, inherit.aes = FALSE) + labs(title = "H1B Visas by county in California", subtitle = "Cities with population >250,000 labeled")
heatmap_tx =  tx_map + geom_point(data = tx_city, aes(long, lat), inherit.aes = FALSE, color = "white", size = 1) + geom_label_repel(data = tx_city, aes(long, lat, label = name), size = 2, inherit.aes = FALSE) + labs(title = "H1B Visas by county in Texas", subtitle = "Cities with population >250,000 labeled")
heatmap_fl = fl_map + geom_point(data = fl_city, aes(long, lat), inherit.aes = FALSE, color = "white", size = 1) + geom_label_repel(data = fl_city, aes(long, lat, label = name), size = 2, inherit.aes = FALSE) + labs(title = "H1B Visas by county in Florida", subtitle = "Cities with population >250,000 labeled")
```


#INTRODUCTION

  In the current American political context, immigration is a hot bed issue. Our current administration has aligned strongly with an isolationist policy; opting to make the process harder and longer to reside legally in this country. A recent study done by the Washington Post determined that in the first two years of Trump's administration, the number of people granted visas by the United States government dropped by twelve percent. Current Trump administration rhetoric leans towards the beliefs that immigrants are causing the United States unnecessary burden and act as a national security liability. As a result, the administration cites these statistically unproven claims as reasons to restrict the flow of immigrants into this country. In order to avoid conclusions not based in reality, our team decided to do a deep dive into the statistics and trends of the H1-B visa dataset collected by the US Department of Labor. It is also important to note that the H1-B visa is given to highly skilled immigrants. These immigrants are highly educated, and generally pursuing or have obtained advanced degrees in technology, medicine, business etc. We posed and examined many questions during our initial data exploration but settled on two distinct questions to gain additional insights from.
  
  Our initial deep dive was to find the underlying principles that impact immigrant salary. We wanted to create a model that would be able to predict an individual's salary given certain parameters. Ideally, this work would be used by either a highly skilled potential immigrant looking to come to the United States to understand how much they should expect to make or a business wanting to learn more about the current market rate for labor. In addition, we wanted to examine the impact of certain individual parameters such as but not limited to; employer location, length of experience, job title, etc. on salary. The ultimate ability for this model is to effectively predict financial compensation given certain parameters.
	
  Our second analysis was focused on the spatial relationship of the number of H1-B Visa holders. We wanted to examine what communities the highest quantity of H1-B visa holders were moving and working. "By endorsing legal immigration cuts, a move he has long supported, Mr. Trump returned to a theme that has defined his short political career and excites his conservative base."(NYTIMES). Trump's traditional, conservative base is strongly located in more rural communities strongly dominated in the Midwest and South. We wanted to investigate if large numbers of immigrants were moving into these pro Trump communities and whether Trump's throttling of legal immigration would even impact the cities and towns where his supporters reside.

#DATA

  The H1-B Visa is a high-skilled immigrant work visa in the United States under the Immigrant and Nationality Act which allows US employers to hire foreign-born workers for specialty occupations in the United States. United States Citizenship and Immigration Services (USCIS) receives over 200,000 H1-B visa applications from US Employers and approves approximately 80,000 applications through a randomized algorithm. The application data and approved application data is available for public access on the Department of Labor website under Annual Disclosure Data.


  For our project we utilized the Prevailing Wage Program data from the Fiscal Year 2018 so the reporting period was from October 1, 2017 to September 30, 2018. For H1-B applications, the prevailing wage is defined as the average wage paid to similarly employed workers in the particular specialty occupation in the area of intended employment. Since USCIS requires that the hiring of an H1-B foreign worker will not adversely affect the wages or the working conditions of US employees working in the same or similar occupation the employer must prevailing wage determination application as a part of the H1-B application for the future employee. Before processing the H1-B application, USCIS will determine whether the salary assigned by the employer for the H1-B employee meets the minimum pay for workers with similar skills, training, and qualifications in the particular specialty occupation through the prevailing wage determination process. Our data set focuses particularly on the prevailing wage determination process.


  Our original data set directly from the DOL website consisted of nearly 57 variables with 149,409 observations. Each observation (row) in this dataset represents a prevailing wage determination application filed by an employer for a particular H1-B candidate. For our first advanced modeling question we thoroughly cleaned the data set in order to focus on 12 variables. Additionally, we removed nearly eight thousand observations with multiple NA fields. The remaining 141,917 observations were divided into a training data set and a test data set. We assigned 106,437 observations to the training set and 35,480 observations to the test set. The following table defines the variables used in our advanced modeling question Q1:

| FIELDS                    | DESCRIPTION                                                                                                                                                                                                                                    |
|---------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| EMPLOYER_CITY             | Address information of the employer that is filing the Prevailing Wage Determination Form.                                                                                                                                                     |
| EMPLOYER_STATE            | Address information of the employer that is filing the Prevailing Wage Determination Form                                                                                                                                                      |
| JOB_TITLE                 | Official title of the employer's job opportunity.                                                                                                                                                                                              |
| TRAVEL_REQUIRED           | Identifies whether travel is required in order for the duties of the employer's job opportunity to be performed.                                                                                                                               |
| PRIMARY EDUCATION LEVEL   | Identifies the minimum U.S. diploma or degree required by the employer for the job opportunity. Valid values include "None," "High School/GED," "Associate's," "Bachelor's," "Master's," "Doctorate (PhD)," and "Other degree (JD, MD, etc.)". |
| SECOND_DIPLOMA            | Identifies if there is an alternate major(s) and/or field(s) of study required by the employer for the job opportunity.Y= Yes; N=No.                                                                                                           |
| TRAINING_REQUIRED         | Identifies whether the employer is requiring training for the job opportunity. Y = Yes; N = No.                                                                                                                                                |
| NUMBER_OF_MONTHS_TRAINING | Identifies the number of months required for training.                                                                                                                                                                                         |
| EMP_EXPERIENCE_REQUIRED   | Identifies whether the employer is requiring employment experience for the job opportunity. Y = Yes; N = No.                                                                                                                                   |
| EMP_EXPERIENCE_MONTHS     | Where employment experience is required, identifies the number of months of employment experience the employer is requiring for the job opportunity.                                                                                           |
| PWD_WAGE_RATE             | Prevailing wage rate issued by the OFLC National Prevailing Wage Center.                                                                                                                                                                       |


  In order to effectively produce an advanced model, an important intermediary step was the thoroughly explore our dataset. We explored the variables in many ways but looking at the distribution of prevailing wages based on education level helped us determine that it was an important variable relationship to explore in our model. Additionally, we examined the spread of H1-B visas throughout the United States in order to determine which states we should further explore in our heatmap analysis. 

```{r echo=FALSE, warning=F, message=F}
wage_data <- data[!is.na(data$PWD_WAGE_RATE),]
level <- c("None", "High School/GED", "Associate's", "Bachelor's", "Master's", "Doctorate (PhD)", "Other Degree (JD, MD, etc.)")
ggplot(wage_data, aes(factor(PRIMARY_EDUCATION_LEVEL, levels = level), PWD_WAGE_RATE)) +
  geom_violin(aes(fill = factor(PRIMARY_EDUCATION_LEVEL))) +
  ggtitle("Distribution of Wages by Education Level") +
  xlab("Primary Education Level") +
  ylab("Prevailing Wage Rate") +
  labs(fill = "Primary Education Level") +
  theme(axis.text.x=element_text(angle=45, hjust=1))
count <- aggregate(cbind(count = VISA_CLASS) ~ PRIMARY_WORKSITE_STATE,
          data = data,
          FUN = function(x){NROW(x)})
count <- count[-c(8,35,40,48),]
count$PRIMARY_WORKSITE_STATE <- tolower(count$PRIMARY_WORKSITE_STATE)
ggplot(count, aes(map_id = PRIMARY_WORKSITE_STATE)) +
  # map points to the fifty_states shape data
  geom_map(aes(fill = count), map = fifty_states) +
  borders("state", colour = "white") +
  scale_fill_gradient(low = "#56B1F7", high = "#132B43", guide = "colorbar") +
  expand_limits(x = fifty_states$long, y = fifty_states$lat) +
  coord_map() +
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  ggtitle("Number of H1B Visa Holders by State") +
  labs(x = "", y = "", fill = "Count") +
  theme(legend.position = "bottom", panel.background = element_blank())
```


# RESULTS

  Our first advanced model was to predict salary based on H1-B visas. We chose to pursue a random forest regression. The reason we chose a random forest was for all the benefits of a decision tree without the overfitting problem. A random forest creates some 'k' trees and averages the results across them all. In this model, we created 500 trees. This gave our regression the time it needed to create an accurate model.

  In order to run the random forest, we needed to remove all of the NA and INF values from the dataset. For some parameters, this just involved removing the entire entry. However, others allowed for a more creative approach. For example, the number of months of experience required was set to NA if no months were required, thus we could replace NA's with zero. After this initial data cleansing, we attempted to run the model. Unfortunately, the first attempt failed because the R random forest class can only handle categorical variables with 53 or less unique categories. To avoid this issue, we switched to a ranger model which is a different random forest class. We initially had a poorly performing model so we began tuning hyperparameters. We printed out the importance for each variable and dropped the lowest ones. This gave a more fine-tuned model and allowed us to keep a larger portion of the data due to no longer needing to drop so many data points because of NA's.

```{r, echo=FALSE}
graph1pred
graph1actual
```

  In our final model, we received an R-squared of 0.78. This means that we have accounted for 78% of variation in salary with our model. We also received a RMSE score of 21,406. While this appears poor at first glance, when normalized for the range of the dependent variable, we received a RMSE of 0.024 or 0.071 with the outliers removed. The variables of most importance in our final model are SUGGESTED_SOC_CODE (industry), PRIMARY_EDUCATION_LEVEL (degree level) and EMP_EXPERIENCE_MONTHS (experience required). Another attempt to improve our model was to remove the outlier of a salary of $980,000. No other H1-B visa received a salary over $300,000. This did not show a large increase in RMSE. We attempted to filter the data even further by removing all values greater than $200,000 and we still did not see a large increase in predictive power. We stuck with the original model to keep things simplest

```{r, echo=FALSE}
graph1imp
```

  Our second analysis looked to expand on the spatial relationship between H1B visa holders. We created heatmaps of the number of H1B visa holders in the three states with the most overall number of H1B visa holders in the Fiscal Year 2018. Within each state, we divide the H1B visa holders by worksite county and for additional context, we also label the cities with populations of over 250,000. In the heatmaps, counties colored with darker shades of blue have higher numbers of H1B visa holders compared to those colored lighter shades. Gray counties are those that have no H1B visa holders in our dataset.  

  In California, the figures show that the greatest number of H1B visa holders are in Los Angeles, San Francisco, Santa Barbara, and Santa Clara counties. These correspond to the major urban areas in California, which is unsurprising given that immigrants generally flock to urban areas. In addition, these are areas where there are a greater number of workers in technology and scientific fields.  
```{r,echo=FALSE}
heatmap_ca
```

In Texas, the county with undoubtedly the most H1B visa holders is Harris County, which includes Houston. Houston generally leans more liberally than the rest of Texas, and is also a center for science and medical research in the state. The number of H1B visa holders in this county makes sense therefore, given the high skill required for these types of occupations.  
```{r,echo=FALSE}
heatmap_tx
```

Similarly, in Florida, H1B visas are concentrated primarily in the counties of Miami-Dade and Alachua. Miami-Dade County is home to Miami, which is a major urban center and leans decidedly Democratic in most elections. Alachua County does not have any major cities with populations of over 250,000, but is home to Gainesville, which houses the University of Florida. The large number of immigrants here can likely be explained due to the presence of the university, which is one of the largest universities in the United States. In general, we can see that the communities where H1B visa holders concentrate tend to be large, commercial centers with industries providing high-skill jobs, such as technology, scientific research, and medicine.  
```{r,echo=FALSE}
heatmap_fl
```


#CONCLUSION


  Our driving principle for conducting this project was to glean meaningful insights from our immigration data. In order to be responsible citizens of our democracy, it is imperative to make our decisions based on strong facts and conclusive data. We examined the impact of certain parameters on immigrant salary as well as the most popular locations for H1-B immigrants. We found that the most H1-B visa holders were working in the states of California, Texas, and Florida. The immigrants were predominately moving to large urban city centers where there is a strong collection of industry sectors like technology, research, and science. Most of these cities lean democratic and are typically centers of research and technology for their states. Our predictive model to find the relationship between salary and dataset parameters found that the most important indicators for determining an immigrant's salary was the SOC_CODE, PRIMARY_EDUCATION, EMP_EXPERIENCE_MONTHS. SOC_CODE is an industry classification developed by the US Department of Labor to group and organize occupations. Our final model predicting salary had a RMSE of $21,406 and a R2 value of 0.78.
	
  Our conclusions seem to be in line with our initial hypothesis. It would make sense that people moving to the United States on the H1-B visa would move to large cities where there is ample opportunity for highly skilled work. Regarding our model, it would also make sense that the most important factors for determining an individual's salary would be the job and industry that they are in, followed closely by their prior experience and education level. The model that was developed has many applications for understanding the way that H1-B visa holders are compensated. The model is incredibly useful for any foreign citizen who wants to estimate their earning potential in the United States. Further investigation could glean additional information about more advanced statistics concerning other factors and parameters. 
    
  We were interested in investigating whether the variables within the prevailing wage determination process had an impact on whether they were accepted. In order to accomplish this feat, we would have to acquire more data. Our current dataset does not state whether or not a visa was accepted or denied. We would need to join the H1-B dataset with our prevailing wage dataset and match based on the visa applicants unique identifier. To create a model to predict acceptance or not we could create a classifying random forest with the classifier being acceptance or rejection. Additionally, we would have to choose new parameters to train our model on. Before developing our random forest model we attempted to join all of our 150,000 observations on case number with another dataset that contained the acceptance or denial status of the H1-B petition. However the formats of the case numbers in both datasets did not match up so we were unsuccessful. The future roadmap for this data analysis would be to join on case number with a dataset that contains this information and adjust the model to predict the final case status of an H1-B petition. 

